{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6971e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>5.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0            1            2            3            4\n",
       "sepal_length          5.1          4.9          4.7          4.6          5.0\n",
       "sepal_width           3.5          3.0          3.2          3.1          3.6\n",
       "petal_length          1.4          1.4          1.3          1.5          1.4\n",
       "petal_width           0.2          0.2          0.2          0.2          0.2\n",
       "species       Iris-setosa  Iris-setosa  Iris-setosa  Iris-setosa  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/IRIS.csv')\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9024777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b287faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_num = {'Iris-setosa': 0 , 'Iris-versicolor':1 , 'Iris-virginica' : 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5968fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species_num'] = df['species'].map(species_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66a25fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species',\n",
       "       'species_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d1061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sepal_length', \n",
    "            'sepal_width', 'petal_length', 'petal_width' ]\n",
    "label = 'species_num'\n",
    "X, y = df[features], df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ee72a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_min_max = min_max_scaler.fit_transform(X)\n",
    "X_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299dd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "                train_test_split(X_min_max,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c275eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297a7294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(X_train.shape[0]*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d66927",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = int(X_train.shape[0]*0.2)\n",
    "\n",
    "#검증데이터\n",
    "validate_X_train = X_train[ :percent]\n",
    "validate_y_train = y_train[ :percent]\n",
    "\n",
    "#학습데이터\n",
    "learn_X_train = X_train[percent : ]\n",
    "learn_y_train = y_train[percent : ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee3b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수 :  (120, 4)\n",
      "검증 데이터 수 :  (24, 4)\n",
      "학습 데이터 수 :  (96, 4)\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 수 : ', X_train.shape)\n",
    "print('검증 데이터 수 : ', validate_X_train.shape)\n",
    "print('학습 데이터 수 : ', learn_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201f8b7",
   "metadata": {},
   "source": [
    "### 모델 생성 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112d26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add( Dense(64, activation='relu', input_dim=4))\n",
    "model.add( Dense(32, activation='relu'))\n",
    "model.add( Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd553c",
   "metadata": {},
   "source": [
    "### loss 학습 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1aed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = 'adam' ,metrics='acc', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad623577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 1.0717 - acc: 0.3750 - val_loss: 1.0374 - val_acc: 0.6667\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0190 - acc: 0.6583 - val_loss: 0.9910 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9719 - acc: 0.6750 - val_loss: 0.9452 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9166 - acc: 0.6750 - val_loss: 0.8918 - val_acc: 0.7500\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8589 - acc: 0.8167 - val_loss: 0.8361 - val_acc: 0.8333\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7987 - acc: 0.9083 - val_loss: 0.7765 - val_acc: 0.8333\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7391 - acc: 0.8250 - val_loss: 0.7180 - val_acc: 0.8333\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6821 - acc: 0.8667 - val_loss: 0.6586 - val_acc: 0.8750\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6243 - acc: 0.9000 - val_loss: 0.6067 - val_acc: 0.8750\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5760 - acc: 0.8917 - val_loss: 0.5612 - val_acc: 0.8750\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5300 - acc: 0.8917 - val_loss: 0.5181 - val_acc: 0.8750\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4913 - acc: 0.8917 - val_loss: 0.4812 - val_acc: 0.8750\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4561 - acc: 0.9333 - val_loss: 0.4502 - val_acc: 0.9167\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4284 - acc: 0.9333 - val_loss: 0.4250 - val_acc: 0.9167\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4004 - acc: 0.9417 - val_loss: 0.4020 - val_acc: 0.9167\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3784 - acc: 0.9250 - val_loss: 0.3815 - val_acc: 0.9167\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3547 - acc: 0.9417 - val_loss: 0.3629 - val_acc: 0.9167\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.9583 - val_loss: 0.3446 - val_acc: 0.9167\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3095 - acc: 0.9417 - val_loss: 0.3273 - val_acc: 0.8750\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2935 - acc: 0.9417 - val_loss: 0.3117 - val_acc: 0.8333\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2827 - acc: 0.9417 - val_loss: 0.2960 - val_acc: 0.9583\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2591 - acc: 0.9333 - val_loss: 0.2837 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2380 - acc: 0.9583 - val_loss: 0.2682 - val_acc: 0.9583\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2216 - acc: 0.9583 - val_loss: 0.2581 - val_acc: 0.8750\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2081 - acc: 0.9583 - val_loss: 0.2448 - val_acc: 0.9583\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1960 - acc: 0.9667 - val_loss: 0.2350 - val_acc: 0.9167\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1828 - acc: 0.9667 - val_loss: 0.2274 - val_acc: 0.9167\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1721 - acc: 0.9583 - val_loss: 0.2190 - val_acc: 0.9167\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1653 - acc: 0.9500 - val_loss: 0.2072 - val_acc: 0.9167\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1659 - acc: 0.9417 - val_loss: 0.2001 - val_acc: 0.9167\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1533 - acc: 0.9583 - val_loss: 0.2068 - val_acc: 0.8750\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1440 - acc: 0.9500 - val_loss: 0.1871 - val_acc: 0.9583\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1329 - acc: 0.9833 - val_loss: 0.1999 - val_acc: 0.8750\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1320 - acc: 0.9583 - val_loss: 0.1754 - val_acc: 0.9167\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1283 - acc: 0.9750 - val_loss: 0.1800 - val_acc: 0.9167\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1213 - acc: 0.9583 - val_loss: 0.1672 - val_acc: 0.9167\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1157 - acc: 0.9750 - val_loss: 0.1736 - val_acc: 0.9167\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1117 - acc: 0.9667 - val_loss: 0.1605 - val_acc: 0.9167\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1104 - acc: 0.9833 - val_loss: 0.1720 - val_acc: 0.8750\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1093 - acc: 0.9500 - val_loss: 0.1513 - val_acc: 0.9167\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1005 - acc: 0.9667 - val_loss: 0.1784 - val_acc: 0.8750\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0996 - acc: 0.9750 - val_loss: 0.1468 - val_acc: 0.9167\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0975 - acc: 0.9583 - val_loss: 0.1463 - val_acc: 0.9167\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1029 - acc: 0.9750 - val_loss: 0.1496 - val_acc: 0.9167\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.9667 - val_loss: 0.1383 - val_acc: 0.9167\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0991 - acc: 0.9500 - val_loss: 0.1527 - val_acc: 0.9167\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0908 - acc: 0.9750 - val_loss: 0.1363 - val_acc: 0.9167\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0898 - acc: 0.9750 - val_loss: 0.1393 - val_acc: 0.9167\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0848 - acc: 0.9583 - val_loss: 0.1398 - val_acc: 0.9167\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0836 - acc: 0.9750 - val_loss: 0.1411 - val_acc: 0.9167\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 0.9750 - val_loss: 0.1295 - val_acc: 0.9167\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0816 - acc: 0.9667 - val_loss: 0.1292 - val_acc: 0.9167\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0775 - acc: 0.9750 - val_loss: 0.1349 - val_acc: 0.9167\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0772 - acc: 0.9750 - val_loss: 0.1327 - val_acc: 0.9167\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0798 - acc: 0.9583 - val_loss: 0.1300 - val_acc: 0.9167\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0796 - acc: 0.9833 - val_loss: 0.1273 - val_acc: 0.9167\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0736 - acc: 0.9667 - val_loss: 0.1218 - val_acc: 0.9167\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0732 - acc: 0.9750 - val_loss: 0.1302 - val_acc: 0.9167\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0740 - acc: 0.9917 - val_loss: 0.1203 - val_acc: 0.9167\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0775 - acc: 0.9667 - val_loss: 0.1130 - val_acc: 0.9167\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0772 - acc: 0.9667 - val_loss: 0.1273 - val_acc: 0.9167\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0687 - acc: 0.9750 - val_loss: 0.1170 - val_acc: 0.9167\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0687 - acc: 0.9667 - val_loss: 0.1120 - val_acc: 0.9167\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0683 - acc: 0.9750 - val_loss: 0.1226 - val_acc: 0.9167\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0697 - acc: 0.9667 - val_loss: 0.1205 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0652 - acc: 0.9750 - val_loss: 0.1193 - val_acc: 0.9167\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0728 - acc: 0.9500 - val_loss: 0.1205 - val_acc: 0.9167\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0669 - acc: 0.9833 - val_loss: 0.1137 - val_acc: 0.9167\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0664 - acc: 0.9750 - val_loss: 0.1216 - val_acc: 0.9583\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0625 - acc: 0.9667 - val_loss: 0.1042 - val_acc: 0.9167\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0713 - acc: 0.9667 - val_loss: 0.1253 - val_acc: 0.9583\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0605 - acc: 0.9750 - val_loss: 0.1040 - val_acc: 0.9167\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0651 - acc: 0.9500 - val_loss: 0.1065 - val_acc: 0.9167\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0736 - acc: 0.9833 - val_loss: 0.1179 - val_acc: 0.9583\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0585 - acc: 0.9833 - val_loss: 0.0984 - val_acc: 0.9167\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0611 - acc: 0.9667 - val_loss: 0.1179 - val_acc: 0.9583\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0634 - acc: 0.9750 - val_loss: 0.1174 - val_acc: 0.9583\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0593 - acc: 0.9750 - val_loss: 0.1015 - val_acc: 0.9167\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0634 - acc: 0.9583 - val_loss: 0.0981 - val_acc: 0.9167\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0587 - acc: 0.9833 - val_loss: 0.1293 - val_acc: 0.9583\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0559 - acc: 0.9917 - val_loss: 0.0971 - val_acc: 0.9167\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0644 - acc: 0.9667 - val_loss: 0.1114 - val_acc: 0.9583\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0578 - acc: 0.9917 - val_loss: 0.0957 - val_acc: 0.9167\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0710 - acc: 0.9583 - val_loss: 0.1010 - val_acc: 0.9583\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0706 - acc: 0.9833 - val_loss: 0.1111 - val_acc: 0.9583\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0608 - acc: 0.9500 - val_loss: 0.0930 - val_acc: 0.9167\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0538 - acc: 0.9833 - val_loss: 0.1081 - val_acc: 0.9583\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - acc: 0.9833 - val_loss: 0.0962 - val_acc: 0.9583\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0568 - acc: 0.9750 - val_loss: 0.1074 - val_acc: 0.9583\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0658 - acc: 0.9583 - val_loss: 0.0852 - val_acc: 0.9583\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0530 - acc: 0.9917 - val_loss: 0.1120 - val_acc: 0.9583\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0577 - acc: 0.9833 - val_loss: 0.1111 - val_acc: 0.9583\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0515 - acc: 0.9833 - val_loss: 0.0880 - val_acc: 0.9167\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0543 - acc: 0.9667 - val_loss: 0.0971 - val_acc: 0.9583\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0545 - acc: 0.9833 - val_loss: 0.1054 - val_acc: 0.9583\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0524 - acc: 0.9833 - val_loss: 0.0962 - val_acc: 0.9583\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0547 - acc: 0.9750 - val_loss: 0.0897 - val_acc: 0.9583\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0601 - acc: 0.9833 - val_loss: 0.0963 - val_acc: 0.9583\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0506 - acc: 0.9833 - val_loss: 0.0918 - val_acc: 0.9583\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0511 - acc: 0.9833 - val_loss: 0.0977 - val_acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, epochs=100, batch_size=10,\n",
    "                validation_data = (validate_X_train, validate_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6bda2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0717129707336426,\n",
       "  1.0189800262451172,\n",
       "  0.9718831181526184,\n",
       "  0.9165647029876709,\n",
       "  0.8589212894439697,\n",
       "  0.7987315058708191,\n",
       "  0.7390932440757751,\n",
       "  0.6820542812347412,\n",
       "  0.6243007779121399,\n",
       "  0.5759695768356323,\n",
       "  0.5300012230873108,\n",
       "  0.49131864309310913,\n",
       "  0.45606720447540283,\n",
       "  0.42835357785224915,\n",
       "  0.4003866910934448,\n",
       "  0.3784198462963104,\n",
       "  0.3546508252620697,\n",
       "  0.3320811688899994,\n",
       "  0.3094596266746521,\n",
       "  0.29346513748168945,\n",
       "  0.28269898891448975,\n",
       "  0.2590669095516205,\n",
       "  0.23796987533569336,\n",
       "  0.22159042954444885,\n",
       "  0.20809966325759888,\n",
       "  0.19596901535987854,\n",
       "  0.18278314173221588,\n",
       "  0.17205862700939178,\n",
       "  0.16528280079364777,\n",
       "  0.16585169732570648,\n",
       "  0.15332238376140594,\n",
       "  0.14402011036872864,\n",
       "  0.13293960690498352,\n",
       "  0.1319592446088791,\n",
       "  0.12828214466571808,\n",
       "  0.12131770700216293,\n",
       "  0.11567449569702148,\n",
       "  0.11174700409173965,\n",
       "  0.1103532686829567,\n",
       "  0.10927252471446991,\n",
       "  0.1004587709903717,\n",
       "  0.09956289827823639,\n",
       "  0.09749767184257507,\n",
       "  0.10290162265300751,\n",
       "  0.08972321450710297,\n",
       "  0.0990631952881813,\n",
       "  0.09084413945674896,\n",
       "  0.08976132422685623,\n",
       "  0.08480051904916763,\n",
       "  0.0836043432354927,\n",
       "  0.08125073462724686,\n",
       "  0.08157798647880554,\n",
       "  0.07745079696178436,\n",
       "  0.0772228091955185,\n",
       "  0.07979332655668259,\n",
       "  0.07955850660800934,\n",
       "  0.07364542037248611,\n",
       "  0.07321980595588684,\n",
       "  0.07399585098028183,\n",
       "  0.07746037095785141,\n",
       "  0.07721230387687683,\n",
       "  0.06871291249990463,\n",
       "  0.06872263550758362,\n",
       "  0.06831546872854233,\n",
       "  0.06973879039287567,\n",
       "  0.06523342430591583,\n",
       "  0.07275940477848053,\n",
       "  0.06692344695329666,\n",
       "  0.06644037365913391,\n",
       "  0.06254240870475769,\n",
       "  0.07133649289608002,\n",
       "  0.06052757799625397,\n",
       "  0.0651291161775589,\n",
       "  0.07359998673200607,\n",
       "  0.05854828283190727,\n",
       "  0.061115480959415436,\n",
       "  0.06336765736341476,\n",
       "  0.059277791529893875,\n",
       "  0.06335261464118958,\n",
       "  0.05872568115592003,\n",
       "  0.05585517734289169,\n",
       "  0.06438735872507095,\n",
       "  0.05784719064831734,\n",
       "  0.07103182375431061,\n",
       "  0.07064399868249893,\n",
       "  0.06080716475844383,\n",
       "  0.05378647521138191,\n",
       "  0.0561615489423275,\n",
       "  0.056761134415864944,\n",
       "  0.06577270478010178,\n",
       "  0.05297012999653816,\n",
       "  0.057736560702323914,\n",
       "  0.05146454647183418,\n",
       "  0.054344043135643005,\n",
       "  0.05447227135300636,\n",
       "  0.05241420120000839,\n",
       "  0.05471830070018768,\n",
       "  0.06014510616660118,\n",
       "  0.05059552192687988,\n",
       "  0.05105101689696312],\n",
       " 'acc': [0.375,\n",
       "  0.6583333611488342,\n",
       "  0.675000011920929,\n",
       "  0.675000011920929,\n",
       "  0.8166666626930237,\n",
       "  0.9083333611488342,\n",
       "  0.824999988079071,\n",
       "  0.8666666746139526,\n",
       "  0.8999999761581421,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.9333333373069763,\n",
       "  0.9333333373069763,\n",
       "  0.9416666626930237,\n",
       "  0.925000011920929,\n",
       "  0.9416666626930237,\n",
       "  0.9583333134651184,\n",
       "  0.9416666626930237,\n",
       "  0.9416666626930237,\n",
       "  0.9416666626930237,\n",
       "  0.9333333373069763,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9583333134651184,\n",
       "  0.949999988079071,\n",
       "  0.9416666626930237,\n",
       "  0.9583333134651184,\n",
       "  0.949999988079071,\n",
       "  0.9833333492279053,\n",
       "  0.9583333134651184,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.9833333492279053,\n",
       "  0.949999988079071,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.949999988079071,\n",
       "  0.9750000238418579,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9750000238418579,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9833333492279053,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9916666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.949999988079071,\n",
       "  0.9833333492279053,\n",
       "  0.9750000238418579,\n",
       "  0.9666666388511658,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.949999988079071,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053,\n",
       "  0.9666666388511658,\n",
       "  0.9750000238418579,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9833333492279053,\n",
       "  0.9916666746139526,\n",
       "  0.9666666388511658,\n",
       "  0.9916666746139526,\n",
       "  0.9583333134651184,\n",
       "  0.9833333492279053,\n",
       "  0.949999988079071,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053,\n",
       "  0.9750000238418579,\n",
       "  0.9583333134651184,\n",
       "  0.9916666746139526,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053,\n",
       "  0.9666666388511658,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053,\n",
       "  0.9750000238418579,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053,\n",
       "  0.9833333492279053],\n",
       " 'val_loss': [1.0374094247817993,\n",
       "  0.9910247921943665,\n",
       "  0.9452106356620789,\n",
       "  0.8917542099952698,\n",
       "  0.8361144065856934,\n",
       "  0.7764932513237,\n",
       "  0.7180247902870178,\n",
       "  0.6585828065872192,\n",
       "  0.606685221195221,\n",
       "  0.5612105131149292,\n",
       "  0.5180661678314209,\n",
       "  0.4812401533126831,\n",
       "  0.4502023160457611,\n",
       "  0.425019234418869,\n",
       "  0.4020122289657593,\n",
       "  0.38145336508750916,\n",
       "  0.36288297176361084,\n",
       "  0.3446168899536133,\n",
       "  0.32730844616889954,\n",
       "  0.3117455840110779,\n",
       "  0.29597851634025574,\n",
       "  0.283704549074173,\n",
       "  0.2682432234287262,\n",
       "  0.2581392824649811,\n",
       "  0.24482078850269318,\n",
       "  0.23504753410816193,\n",
       "  0.22738832235336304,\n",
       "  0.2189885377883911,\n",
       "  0.207240030169487,\n",
       "  0.2000720053911209,\n",
       "  0.206782266497612,\n",
       "  0.18713009357452393,\n",
       "  0.1999213695526123,\n",
       "  0.1753728836774826,\n",
       "  0.18000394105911255,\n",
       "  0.1671748161315918,\n",
       "  0.17363719642162323,\n",
       "  0.16053588688373566,\n",
       "  0.17202158272266388,\n",
       "  0.15125340223312378,\n",
       "  0.17843879759311676,\n",
       "  0.1467561423778534,\n",
       "  0.1463324874639511,\n",
       "  0.1495848298072815,\n",
       "  0.13829238712787628,\n",
       "  0.15273231267929077,\n",
       "  0.13630695641040802,\n",
       "  0.13926661014556885,\n",
       "  0.13981060683727264,\n",
       "  0.14106367528438568,\n",
       "  0.12950628995895386,\n",
       "  0.12922681868076324,\n",
       "  0.1348879486322403,\n",
       "  0.1327257603406906,\n",
       "  0.130013570189476,\n",
       "  0.1273368000984192,\n",
       "  0.121839739382267,\n",
       "  0.1302381306886673,\n",
       "  0.12027863413095474,\n",
       "  0.11301235109567642,\n",
       "  0.12730255722999573,\n",
       "  0.11695569008588791,\n",
       "  0.11199889332056046,\n",
       "  0.12259873002767563,\n",
       "  0.12053057551383972,\n",
       "  0.1192815899848938,\n",
       "  0.12048742920160294,\n",
       "  0.11366170644760132,\n",
       "  0.12161468714475632,\n",
       "  0.10415611416101456,\n",
       "  0.12531974911689758,\n",
       "  0.1040278896689415,\n",
       "  0.10649773478507996,\n",
       "  0.11787160485982895,\n",
       "  0.09837176650762558,\n",
       "  0.11790221929550171,\n",
       "  0.11744336038827896,\n",
       "  0.10152726620435715,\n",
       "  0.09813312441110611,\n",
       "  0.12927760183811188,\n",
       "  0.09712561219930649,\n",
       "  0.11141681671142578,\n",
       "  0.09571244567632675,\n",
       "  0.10095382481813431,\n",
       "  0.11111565679311752,\n",
       "  0.09295040369033813,\n",
       "  0.10814795643091202,\n",
       "  0.0961807370185852,\n",
       "  0.10739141702651978,\n",
       "  0.08515394479036331,\n",
       "  0.11198770999908447,\n",
       "  0.11113566905260086,\n",
       "  0.08795062452554703,\n",
       "  0.0971238911151886,\n",
       "  0.10542654991149902,\n",
       "  0.09621873497962952,\n",
       "  0.08970566838979721,\n",
       "  0.09633637219667435,\n",
       "  0.09183772653341293,\n",
       "  0.09773559123277664],\n",
       " 'val_acc': [0.6666666865348816,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.875,\n",
       "  0.8333333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.8333333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.875,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.875,\n",
       "  0.9583333134651184,\n",
       "  0.875,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.875,\n",
       "  0.9166666865348816,\n",
       "  0.875,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9166666865348816,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184,\n",
       "  0.9583333134651184]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fa9f0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1287 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12874624133110046, 0.9333333373069763]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ccfeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9070757e-04, 9.8761332e-01, 1.2095956e-02],\n",
       "       [5.5001286e-04, 9.8384839e-01, 1.5601557e-02],\n",
       "       [9.9789751e-01, 2.1024263e-03, 7.5841342e-09],\n",
       "       [9.9884951e-01, 1.1505011e-03, 2.8028906e-09],\n",
       "       [9.9981207e-01, 1.8793624e-04, 2.2778245e-10],\n",
       "       [1.2444406e-04, 3.4045202e-01, 6.5942347e-01],\n",
       "       [5.4847067e-07, 4.2343424e-03, 9.9576509e-01],\n",
       "       [4.7182332e-04, 9.9502087e-01, 4.5072325e-03],\n",
       "       [9.5252568e-01, 4.7473509e-02, 8.5119194e-07],\n",
       "       [1.9095378e-04, 9.8764229e-01, 1.2166747e-02],\n",
       "       [9.9878806e-01, 1.2119717e-03, 3.6287719e-09],\n",
       "       [7.5907492e-06, 1.1874949e-02, 9.8811740e-01],\n",
       "       [1.9898584e-05, 1.2863469e-01, 8.7134540e-01],\n",
       "       [1.0869119e-03, 9.9851102e-01, 4.0204739e-04],\n",
       "       [1.1824672e-07, 8.0410921e-04, 9.9919575e-01],\n",
       "       [9.9863511e-01, 1.3648479e-03, 5.4786051e-09],\n",
       "       [1.5074525e-04, 8.5819602e-01, 1.4165327e-01],\n",
       "       [9.9833423e-01, 1.6657995e-03, 3.6989720e-09],\n",
       "       [9.9983454e-01, 1.6538714e-04, 1.2546103e-10],\n",
       "       [1.2082580e-03, 9.9125731e-01, 7.5344383e-03],\n",
       "       [8.8455919e-05, 2.1656281e-01, 7.8334880e-01],\n",
       "       [1.3087018e-04, 9.8194826e-01, 1.7920857e-02],\n",
       "       [9.9928647e-01, 7.1357872e-04, 1.5639204e-09],\n",
       "       [9.9571383e-01, 4.2861602e-03, 1.9483304e-08],\n",
       "       [6.3260067e-08, 2.4767569e-04, 9.9975222e-01],\n",
       "       [2.1245292e-05, 8.0167055e-02, 9.1981167e-01],\n",
       "       [9.9754721e-01, 2.4527712e-03, 1.5993749e-08],\n",
       "       [2.7896696e-05, 5.8016646e-01, 4.1980565e-01],\n",
       "       [4.6541385e-04, 9.9841726e-01, 1.1173107e-03],\n",
       "       [1.9499209e-08, 7.2688365e-04, 9.9927312e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51581b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00029071, 0.9876133 , 0.01209596],\n",
       "       [0.00055001, 0.9838484 , 0.01560156],\n",
       "       [0.9978975 , 0.00210243, 0.00000001],\n",
       "       [0.9988495 , 0.0011505 , 0.        ],\n",
       "       [0.99981207, 0.00018794, 0.        ],\n",
       "       [0.00012444, 0.34045202, 0.6594235 ],\n",
       "       [0.00000055, 0.00423434, 0.9957651 ],\n",
       "       [0.00047182, 0.99502087, 0.00450723],\n",
       "       [0.9525257 , 0.04747351, 0.00000085],\n",
       "       [0.00019095, 0.9876423 , 0.01216675],\n",
       "       [0.99878806, 0.00121197, 0.        ],\n",
       "       [0.00000759, 0.01187495, 0.9881174 ],\n",
       "       [0.0000199 , 0.12863469, 0.8713454 ],\n",
       "       [0.00108691, 0.998511  , 0.00040205],\n",
       "       [0.00000012, 0.00080411, 0.99919575],\n",
       "       [0.9986351 , 0.00136485, 0.00000001],\n",
       "       [0.00015075, 0.858196  , 0.14165327],\n",
       "       [0.9983342 , 0.0016658 , 0.        ],\n",
       "       [0.99983454, 0.00016539, 0.        ],\n",
       "       [0.00120826, 0.9912573 , 0.00753444],\n",
       "       [0.00008846, 0.21656281, 0.7833488 ],\n",
       "       [0.00013087, 0.98194826, 0.01792086],\n",
       "       [0.9992865 , 0.00071358, 0.        ],\n",
       "       [0.99571383, 0.00428616, 0.00000002],\n",
       "       [0.00000006, 0.00024768, 0.9997522 ],\n",
       "       [0.00002125, 0.08016706, 0.91981167],\n",
       "       [0.9975472 , 0.00245277, 0.00000002],\n",
       "       [0.0000279 , 0.58016646, 0.41980565],\n",
       "       [0.00046541, 0.99841726, 0.00111731],\n",
       "       [0.00000002, 0.00072688, 0.9992731 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pred= model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3702c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 2, 2, 1, 2, 0, 1, 0, 0, 1, 2, 1,\n",
       "       0, 0, 2, 2, 0, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = np.argmax( model.predict(X_test), axis=1)\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac5e8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63     1\n",
       "53     1\n",
       "1      0\n",
       "9      0\n",
       "22     0\n",
       "127    2\n",
       "112    2\n",
       "55     1\n",
       "41     0\n",
       "86     1\n",
       "26     0\n",
       "121    2\n",
       "116    2\n",
       "81     1\n",
       "120    2\n",
       "3      0\n",
       "133    2\n",
       "31     0\n",
       "46     0\n",
       "59     1\n",
       "149    2\n",
       "52     1\n",
       "35     0\n",
       "23     0\n",
       "100    2\n",
       "110    2\n",
       "8      0\n",
       "129    2\n",
       "71     1\n",
       "105    2\n",
       "Name: species_num, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c7ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_label ==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c5d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f34278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
